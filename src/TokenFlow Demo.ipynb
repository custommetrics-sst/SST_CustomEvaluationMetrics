{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/omerbt/TokenFlow.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMbucHB9S0_Q",
        "outputId": "cc6981d4-42da-455d-fbd1-fea4ce4fa215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TokenFlow'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 55 (delta 16), reused 37 (delta 9), pack-reused 5 (from 1)\u001b[K\n",
            "Receiving objects: 100% (55/55), 28.08 MiB | 8.79 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd TokenFlow\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7b6KEJXe1tM",
        "outputId": "1894b220-e847-4dd5-c6d8-6f81b5522a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TokenFlow\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (11.0.0)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.31.0)\n",
            "Collecting ftfy (from -r requirements.txt (line 3))\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.46.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.10.0.84)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.66.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.26.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.1.1)\n",
            "Collecting xformers (from -r requirements.txt (line 10))\n",
            "  Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.17.1)\n",
            "Collecting av (from -r requirements.txt (line 12))\n",
            "  Downloading av-13.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting kornia (from -r requirements.txt (line 13))\n",
            "  Downloading kornia-0.7.4-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers->-r requirements.txt (line 2)) (8.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers->-r requirements.txt (line 2)) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from diffusers->-r requirements.txt (line 2)) (0.26.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers->-r requirements.txt (line 2)) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers->-r requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers->-r requirements.txt (line 2)) (0.4.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->-r requirements.txt (line 3)) (0.2.13)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 4)) (24.2)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 4)) (0.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 9)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 9)) (2.5.1+cu121)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate->-r requirements.txt (line 9)) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.67.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 11)) (3.1.3)\n",
            "Collecting kornia-rs>=0.1.0 (from kornia->-r requirements.txt (line 13))\n",
            "  Downloading kornia_rs-0.1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 11)) (3.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers->-r requirements.txt (line 2)) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers->-r requirements.txt (line 2)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers->-r requirements.txt (line 2)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers->-r requirements.txt (line 2)) (2024.8.30)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-13.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia-0.7.4-py2.py3-none-any.whl (899 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.4/899.4 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kornia-rs, ftfy, av, xformers, kornia\n",
            "Successfully installed av-13.1.0 ftfy-6.3.1 kornia-0.7.4 kornia-rs-0.1.7 xformers-0.0.28.post3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python preprocess.py --data_path '/content/TokenFlow/data/wolf.mp4' --inversion_prompt 'a wolf is watching around' --n_frames 16"
      ],
      "metadata": {
        "id": "Dev6uTUtjTIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python run_tokenflow_pnp.py"
      ],
      "metadata": {
        "id": "mjnQDroJludE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "videos_prompt_dic = {\n",
        "\n",
        "'A car is moving on an empty road' :  ['1. a black car is moving on empty road','3. a bus is moving on empty road', '21. a truck is moving on empty road' ] ,\n",
        " 'A clown fish swimming in a coral reef':  ['6. a dolphin is swimming in a coral reef', '17. a shark is swimming in a coral reef', '20. a tortoise is swimming in a coral reef', '8. a fish is swimming in empty ocean'],\n",
        " 'A duck diving underwater in search of food': ['7. a dolphin is swimming under water in search of food', '16. a seagull is diving under water insearch of food', '26. an octopus is diving under water in search of food', '27. fish is diving under water in search of food'],\n",
        " 'A rabbit walking on the ground': ['11. a mouse is walking on the ground', '13. a porcupine is walking on the ground', '14. a rabbit is walking in the forest'],\n",
        " 'A skateboarder performing tricks at a skate park': ['15. a robot is skateboarding at skate park', '22. a woman is skateboarding at skate park', '24. an alien is skateboarding at skate park'],\n",
        " 'A white cat walking on the grass': ['2. a black cat is walking on the ground', '10. a lion is walking on the ground', '19. a tiger is walking on the ground', '5. a dog is walking on the ground'],\n",
        " 'A white horse galloping on a street': ['9. a lion is running on the ground', '23. a zebra is running on the ground', '25. an elephant is running on the ground'],\n",
        " 'a mallard is swimiing in water': ['4. a crocodile is swimming in the water', '12. a pigeon is swimming in the water', '18. a swan is swimming in the water', '']\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "_Vm7JxSUmac_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python preprocess.py --data_path '/content/TokenFlow/data/a mallard is swimiing in water.mp4' --inversion_prompt 'a mallard is swimiing in water' --n_frames 16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFR2420i5Xb0",
        "outputId": "67378c3a-8c84-4779-efba-3f57eafdb962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-20 03:43:20.195944: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-11-20 03:43:20.212659: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-20 03:43:20.233681: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-20 03:43:20.239992: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-20 03:43:20.254962: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-20 03:43:21.397206: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "A matching Triton is not available, some optimizations will not be enabled\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xformers/__init__.py\", line 57, in _is_triton_available\n",
            "    import triton  # noqa\n",
            "ModuleNotFoundError: No module named 'triton'\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/io/video.py:169: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n",
            "  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n",
            "[INFO] loading stable diffusion...\n",
            "/usr/local/lib/python3.10/dist-packages/diffusers/utils/hub_utils.py:338: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "An error occurred while trying to fetch stabilityai/stable-diffusion-2-1-base: stabilityai/stable-diffusion-2-1-base does not appear to have a file named diffusion_pytorch_model.safetensors.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "/usr/local/lib/python3.10/dist-packages/diffusers/utils/hub_utils.py:338: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
            " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
            "  warnings.warn(\n",
            "An error occurred while trying to fetch stabilityai/stable-diffusion-2-1-base: stabilityai/stable-diffusion-2-1-base does not appear to have a file named diffusion_pytorch_model.safetensors.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "[INFO] loaded stable diffusion!\n",
            "100% 500/500 [03:32<00:00,  2.36it/s]\n",
            "100% 500/500 [03:32<00:00,  2.36it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "# File path to the YAML file\n",
        "file_path = \"/content/TokenFlow/configs/config_pnp.yaml\"\n",
        "\n",
        "# Load the existing YAML content\n",
        "with open(file_path, \"r\") as file:\n",
        "    config = yaml.safe_load(file)\n",
        "\n",
        "#config['n_inversion_steps'] = 50\n",
        "config['data_path'] = 'data/a mallard is swimiing in water'  # Change video path, no .mp4\n",
        "config['prompt'] = 'a swan is swimming in the water'  # Change inversion prompt\n",
        "# config['n_frames'] = 16  # Update number of frames\n",
        "\n",
        "# Save the updated content back to the same file\n",
        "with open(file_path, \"w\") as file:\n",
        "    yaml.dump(config, file, default_flow_style=False)"
      ],
      "metadata": {
        "id": "1IsqXiqz53ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_tokenflow_pnp.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5GY57xB5z5y",
        "outputId": "35a8a67f-8ef1-4216-a11c-26569ec4fb18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-20 04:31:20.121478: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-20 04:31:20.142426: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-20 04:31:20.148782: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-20 04:31:21.174875: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "A matching Triton is not available, some optimizations will not be enabled\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xformers/__init__.py\", line 57, in _is_triton_available\n",
            "    import triton  # noqa\n",
            "ModuleNotFoundError: No module named 'triton'\n",
            "{'batch_size': 8, 'data_path': 'data/a mallard is swimiing in water', 'device': 'cuda', 'guidance_scale': 7.5, 'latents_path': 'latents', 'n_frames': 40, 'n_inversion_steps': 500, 'n_timesteps': 50, 'negative_prompt': 'ugly, blurry, low res, unrealistic, unaesthetic', 'output_path': 'tokenflow-results_pnp_SD_2.1/a mallard is swimiing in water/a swan is swimming in the water/attn_0.5_f_0.8/batch_size_8/50', 'pnp_attn_t': 0.5, 'pnp_f_t': 0.8, 'prompt': 'a swan is swimming in the water', 'sd_version': '2.1', 'seed': 1}\n",
            "Loading SD model\n",
            "Loading pipeline components...: 100% 6/6 [00:01<00:00,  4.74it/s]\n",
            "SD model loaded\n",
            "Number of frames:  16\n",
            "/content/TokenFlow/run_tokenflow_pnp.py:189: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  noisy_latent = torch.load(latents_path)[indices].to(self.device)\n",
            "Sampling:   0% 0/50 [00:00<?, ?it/s]/content/TokenFlow/tokenflow_utils.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  latents = torch.load(latents_t_path)\n",
            "Sampling: 100% 50/50 [01:43<00:00,  2.07s/it]\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NNx7WR8tYt-W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}